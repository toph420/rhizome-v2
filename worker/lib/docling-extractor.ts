/**
 * Docling PDF Extraction - TypeScript Bridge with HybridChunker Support
 *
 * Integrates Python Docling library via child_process for local PDF extraction.
 * Provides 100% reliable extraction with optional semantic chunking.
 *
 * Phase 2: Added HybridChunker integration for structural metadata extraction
 */

import { spawn } from 'child_process'
import { promises as fs } from 'fs'
import path from 'path'
import os from 'os'
import { fileURLToPath } from 'url'

// ESM equivalent of __dirname
const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// ============================================================================
// NEW: Phase 2 Types for HybridChunker Support
// ============================================================================

/**
 * Chunk structure from Docling HybridChunker.
 * Contains content and rich structural metadata.
 */
export interface DoclingChunk {
  /** Chunk index in document (0-based) */
  index: number
  /** Chunk text content */
  content: string
  /** Rich metadata from Docling */
  meta: {
    /** Starting page number (1-based) */
    page_start?: number
    /** Ending page number (1-based) */
    page_end?: number
    /** Heading path (e.g., ["Chapter 1", "Section 1.1"]) */
    heading_path?: string[]
    /** Heading level (depth in TOC) */
    heading_level?: number
    /** Section marker (for EPUB support) */
    section_marker?: string
    /** Bounding boxes for PDF coordinate highlighting */
    bboxes?: Array<{
      page: number
      l: number  // left
      t: number  // top
      r: number  // right
      b: number  // bottom
    }>

    // Phase 2A enhancements
    /** Character range in cleaned markdown (before chunking) - enables 99%+ annotation accuracy */
    charspan?: [number, number]
    /** Content layer: BODY, FURNITURE, BACKGROUND, INVISIBLE, NOTES */
    content_layer?: string
    /** Content type: PARAGRAPH, CODE, FORMULA, LIST_ITEM, CAPTION, etc. */
    content_label?: string
    /** Explicit section level (1-100) from Docling structure */
    section_level?: number
    /** Whether list is enumerated (numbered) */
    list_enumerated?: boolean
    /** List marker: "1.", "â€¢", "a)", etc. */
    list_marker?: string
    /** Programming language for code blocks */
    code_language?: string
    /** Hyperlink URL or file path */
    hyperlink?: string
  }
}

/**
 * Document structure extracted from Docling.
 * Provides heading hierarchy for table of contents.
 */
export interface DoclingStructure {
  /** Extracted headings with hierarchy */
  headings: Array<{
    level: number
    text: string
    page: number | null
  }>
  /** Total number of pages in document */
  total_pages: number
  /** Document sections (reserved for future use) */
  sections: any[]
}

/**
 * Extraction result from Docling Python script.
 * Now includes optional chunks and structure.
 */
export interface DoclingExtractionResult {
  /** Extracted markdown content */
  markdown: string
  /** Document structure (headings, pages) */
  structure: DoclingStructure
  /** Chunks with metadata (only if enableChunking=true) */
  chunks?: DoclingChunk[]
}

// ============================================================================
// Enhanced Options Interface
// ============================================================================

export interface DoclingOptions {
  /** Enable HybridChunker for semantic chunking (Phase 2) */
  enableChunking?: boolean
  /** Chunk size in tokens (default: 512) */
  chunkSize?: number
  /** Tokenizer model name (default: 'Xenova/all-mpnet-base-v2') */
  tokenizer?: string
  /** Enable OCR for scanned PDFs (slower) */
  ocr?: boolean
  /** Maximum number of pages to process (for testing) */
  maxPages?: number
  /** Page range to extract [start, end] (1-indexed) */
  pageRange?: [number, number]
  /** Timeout in milliseconds (default: 10 minutes) */
  timeout?: number
  /** Python executable path (default: python3) */
  pythonPath?: string
  /** Progress callback */
  onProgress?: (percent: number, stage: string, message: string) => void
}

// ============================================================================
// Progress Type (Enhanced)
// ============================================================================

export interface DoclingProgress {
  type: 'progress'
  /** Stage: 'extraction' or 'chunking' */
  stage: string
  /** Progress percentage (0-100) */
  percent: number
  /** Human-readable status message */
  message: string
}

// ============================================================================
// Core Extraction Functions
// ============================================================================

/**
 * Extract PDF using Docling (Python) via child process.
 * Now supports optional HybridChunker integration.
 *
 * @param pdfPath - Path to PDF file (absolute path)
 * @param options - Extraction and chunking options
 * @returns Extracted markdown, structure, and optional chunks
 * @throws Error if extraction fails
 *
 * @example
 * // Without chunking (cloud mode, backward compatible)
 * const result = await extractWithDocling('/tmp/document.pdf', {
 *   enableChunking: false
 * })
 *
 * @example
 * // With chunking (local mode, Phase 2+)
 * const result = await extractWithDocling('/tmp/document.pdf', {
 *   enableChunking: true,
 *   chunkSize: 512,
 *   tokenizer: 'Xenova/all-mpnet-base-v2',
 *   onProgress: (percent, stage, message) => {
 *     console.log(`${stage}: ${percent}% - ${message}`)
 *   }
 * })
 */
export async function extractWithDocling(
  pdfPath: string,
  options: DoclingOptions = {}
): Promise<DoclingExtractionResult> {
  const startTime = Date.now()

  // Validate PDF path
  const pdfAbsPath = path.resolve(pdfPath)
  const pdfExists = await fs.access(pdfAbsPath).then(() => true).catch(() => false)

  if (!pdfExists) {
    throw new Error(`PDF file not found: ${pdfAbsPath}`)
  }

  // Prepare options for Python script
  const pythonOptions: Record<string, any> = {
    // Phase 2: Chunking options
    enable_chunking: options.enableChunking || false,
    chunk_size: options.chunkSize || 512,
    tokenizer: options.tokenizer || 'Xenova/all-mpnet-base-v2',
    // Legacy options
    ocr: options.ocr || false,
    max_pages: options.maxPages,
    page_range: options.pageRange
  }

  const scriptPath = path.join(__dirname, '../scripts/docling_extract.py')
  const pythonPath = options.pythonPath || 'python3'
  const timeout = options.timeout || 10 * 60 * 1000 // 10 minutes default (Phase 2: increased from 30 min)

  console.log('[Docling] Starting extraction...')
  console.log(`  PDF: ${pdfAbsPath}`)
  console.log(`  Mode: ${pythonOptions.enable_chunking ? 'LOCAL (with chunking)' : 'CLOUD (no chunking)'}`)
  console.log(`  Options: ${JSON.stringify(pythonOptions)}`)

  return runDoclingScript(scriptPath, pdfAbsPath, pythonOptions, pythonPath, timeout, options.onProgress)
}

/**
 * Run Docling Python script via subprocess.
 * Handles progress messages and structured output parsing.
 *
 * CRITICAL: Python must flush stdout after every write or IPC hangs.
 * Pattern from Phase 2: worker/lib/docling-extractor.ts:120-220
 */
async function runDoclingScript(
  scriptPath: string,
  pdfPath: string,
  options: any,
  pythonPath: string,
  timeout: number,
  onProgress?: (percent: number, stage: string, message: string) => void
): Promise<DoclingExtractionResult> {
  return new Promise((resolve, reject) => {
    // Spawn Python process with unbuffered output
    // -u flag is CRITICAL for real-time progress
    const python = spawn(pythonPath, [
      '-u',  // Unbuffered output
      scriptPath,
      pdfPath,
      JSON.stringify(options)
    ], {
      env: { ...process.env, PYTHONUNBUFFERED: '1' },
      stdio: ['ignore', 'pipe', 'pipe']
    })

    let stdoutData = ''
    let stderrData = ''
    let result: DoclingExtractionResult | null = null
    let lineBuffer = ''  // Buffer for incomplete lines

    // Set timeout (10 minutes for large PDFs)
    const timeoutHandle = setTimeout(() => {
      python.kill('SIGTERM')
      reject(new Error(`Docling extraction timeout after ${timeout}ms`))
    }, timeout)

    // Handle stdout (progress + final result)
    // CRITICAL: Large JSON output arrives in multiple chunks
    python.stdout.on('data', (data: Buffer) => {
      // Append new data to buffer
      lineBuffer += data.toString()

      // Split by newlines
      const lines = lineBuffer.split('\n')

      // Process all complete lines (all but the last, which may be incomplete)
      for (let i = 0; i < lines.length - 1; i++) {
        const line = lines[i].trim()
        if (!line) continue

        try {
          const message = JSON.parse(line)

          if (message.type === 'progress' && onProgress) {
            // Progress update from Python
            onProgress(message.percent, message.stage, message.message)
          } else if (message.type === 'result') {
            // Final result
            result = message.data
            console.log('[Docling] Received complete result JSON')
          } else if (message.type === 'error') {
            // Structured error from Python
            reject(new Error(`Docling error: ${message.error}\n${message.traceback || ''}`))
          }
        } catch (e) {
          // Not JSON, might be debug output - accumulate for error reporting
          stdoutData += line + '\n'
        }
      }

      // Keep the last (potentially incomplete) line in the buffer
      lineBuffer = lines[lines.length - 1]
    })

    // Handle stderr (Python errors)
    python.stderr.on('data', (data: Buffer) => {
      stderrData += data.toString()
    })

    // Handle process exit
    python.on('close', (code) => {
      clearTimeout(timeoutHandle)

      if (code === 0 && result) {
        // Success
        console.log('[Docling] Extraction complete')
        console.log(`  Structure: ${result.structure.total_pages} pages, ${result.structure.headings.length} headings`)
        if (result.chunks) {
          console.log(`  Chunks: ${result.chunks.length} segments`)
        }
        console.log(`  Markdown size: ${Math.round(result.markdown.length / 1024)}KB`)

        resolve(result)
      } else if (code === 0 && !result) {
        // Exit 0 but no result - parsing error
        reject(new Error(
          'Docling script completed but returned no result\n' +
          `stdout: ${stdoutData.slice(0, 500)}\n` +
          `stderr: ${stderrData.slice(0, 500)}`
        ))
      } else {
        // Non-zero exit code
        let errorMessage = `Docling script failed (exit code ${code})`

        if (stderrData) {
          errorMessage += `\nstderr: ${stderrData}`
        }
        if (stdoutData) {
          errorMessage += `\nstdout: ${stdoutData.slice(0, 500)}`
        }

        reject(new Error(errorMessage))
      }
    })

    // Handle process errors (e.g., Python not found)
    python.on('error', (error) => {
      clearTimeout(timeoutHandle)

      if (error.message.includes('ENOENT')) {
        reject(new Error(
          'Python not found. Install Python 3.10+ and ensure it is in PATH.\n' +
          `Tried to execute: ${pythonPath}`
        ))
      } else {
        reject(new Error(`Failed to spawn Python process: ${error.message}`))
      }
    })
  })
}

/**
 * Extract PDF from buffer (saves to temp file first).
 * Convenience wrapper for extractWithDocling.
 *
 * @param pdfBuffer - PDF file as ArrayBuffer or Buffer
 * @param options - Extraction and chunking options
 * @returns Extracted markdown, structure, and optional chunks
 */
export async function extractPdfBuffer(
  pdfBuffer: ArrayBuffer | Buffer,
  options: DoclingOptions = {}
): Promise<DoclingExtractionResult> {
  // Save to temp file
  const tempDir = os.tmpdir()
  const tempPath = path.join(tempDir, `docling-${Date.now()}.pdf`)

  const buffer = Buffer.isBuffer(pdfBuffer) ? pdfBuffer : Buffer.from(pdfBuffer)
  await fs.writeFile(tempPath, buffer)

  console.log(`[Docling] Saved PDF to temp file: ${tempPath} (${Math.round(buffer.length / 1024)}KB)`)

  try {
    const result = await extractWithDocling(tempPath, options)
    return result
  } finally {
    // Cleanup temp file
    await fs.unlink(tempPath).catch(() => {})
    console.log('[Docling] Cleaned up temp file')
  }
}

// ============================================================================
// Validation Utilities (Phase 2)
// ============================================================================

/**
 * Validate Docling chunks have required metadata.
 * Useful for debugging and ensuring data quality.
 *
 * @param chunks - Array of chunks to validate
 * @returns Validation result with errors
 *
 * @example
 * const validation = validateDoclingChunks(result.chunks)
 * if (!validation.valid) {
 *   console.warn('Chunk validation failed:', validation.errors)
 * }
 */
export function validateDoclingChunks(chunks: DoclingChunk[]): {
  valid: boolean
  errors: string[]
} {
  const errors: string[] = []

  for (const chunk of chunks) {
    // Check content exists
    if (!chunk.content || chunk.content.length === 0) {
      errors.push(`Chunk ${chunk.index} has no content`)
    }

    // Check page numbers exist (critical for citations)
    if (chunk.meta.page_start === null && chunk.meta.page_end === null) {
      errors.push(`Chunk ${chunk.index} missing page numbers`)
    }

    // Check heading path exists (important for structure)
    if (!chunk.meta.heading_path || chunk.meta.heading_path.length === 0) {
      // This is a warning, not error - some chunks may not be under headings
      // errors.push(`Chunk ${chunk.index} missing heading path`)
    }
  }

  return {
    valid: errors.length === 0,
    errors
  }
}
